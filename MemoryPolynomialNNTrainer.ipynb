{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47b108f1-30cb-4320-81cc-6b579d729650",
   "metadata": {},
   "source": [
    "# Подключение библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8d39f99-c818-4df1-a19b-4a8e249bb7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 00:06:23.369835: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-25 00:06:24.243458: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import uuid\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display, HTML, Markdown\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40d00cb-977c-4c75-8be2-04bc037e5266",
   "metadata": {},
   "source": [
    "# Импорт и анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22af300a-9f29-44e0-9b35-82a2fefc3e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('Amp_C_train.txt')\n",
    "except:\n",
    "    for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "        for filename in filenames:\n",
    "            print(os.path.join(dirname, filename))\n",
    "            \n",
    "    df = pd.read_csv(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7995e1c-83ee-40a9-b12e-93fc38bb10ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 172032 entries, 0 to 172031\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    172032 non-null  float64\n",
      " 1   Input   172032 non-null  object \n",
      " 2   Output  172032 non-null  object \n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf2aceb-2cae-4e24-9a7e-af0a5dd5b837",
   "metadata": {},
   "source": [
    "## Проверка наличия CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a401d8ae-22c0-446b-84b2-2805c314d57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!\n",
      "Device name: NVIDIA GeForce GTX 1650 Ti\n",
      "CUDA capability: (7, 5)\n",
      "Driver version: 12.1\n",
      "Device count: 1\n",
      "Current device: 0\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(\"CUDA is available!\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA capability: {torch.cuda.get_device_capability(0)}\")\n",
    "    print(f\"Driver version: {torch.version.cuda}\")\n",
    "    print(f\"Device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Running on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06658b53-2a28-4bc3-a97c-feecffa2e032",
   "metadata": {},
   "source": [
    "## Создание нейросети"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87477df6-6f9b-4e1b-9b7e-d9ba995b81da",
   "metadata": {},
   "source": [
    "### Memory Polynomial (MP) модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e130375-09e5-45ae-a018-3402b526c9b7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MemoryPolynomialNNTrainer:\n",
    "    def __init__(self, df, M, K, batch_size=64, learning_rate=0.001, epochs=10, hidden_layers=[64, 128], dropout_rate=0.5, l1_lambda=0.0, l2_lambda=0.0, patience=2, factor=0.9, edit_model=None, device=None, experiment_name=None):\n",
    "        \"\"\"\n",
    "        Инициализация класса для тренировки модели Memory Polynomial с использованием нейронных сетей.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Входные данные.\n",
    "            M (int): Глубина памяти.\n",
    "            K (int): Степень полинома.\n",
    "            batch_size (int, optional): Размер батча для обучения. По умолчанию 64.\n",
    "            learning_rate (float, optional): Скорость обучения для оптимизатора. По умолчанию 0.001.\n",
    "            epochs (int, optional): Количество эпох. По умолчанию 10.\n",
    "            hidden_layers (list, optional): Конфигурация скрытых слоев. По умолчанию [64, 128].\n",
    "            device (str, optional): Устройство для выполнения вычислений ('cpu' или 'cuda'). По умолчанию None.\n",
    "            experiment_name(str, optional): Название эксперимента. По умолчанию None.\n",
    "        \"\"\"\n",
    "        # Подготовка данных\n",
    "        self.df = self.prepare_data(df)\n",
    "        self.device = self.get_device(device)\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.M = M\n",
    "        self.K = K\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.l1_lambda = l1_lambda\n",
    "        self.l2_lambda = l2_lambda\n",
    "        self.history = {\"epoch\": [], \"rmse\": []} # История обучения\n",
    "        self.model_id = str(uuid.uuid4()) # Генерация уникального ID\n",
    "        self.experiment_name = 'memory_polynomial' if not experiment_name else experiment_name\n",
    "        self.writer = self.initialize_log_dir(self.experiment_name)\n",
    "\n",
    "        # Подготовка данных\n",
    "        self.X, self.y, self.times = self.create_dataset(self.df, M, K)\n",
    "        self.dataset = TensorDataset(\n",
    "            torch.tensor(self.X, dtype=torch.float32),\n",
    "            torch.tensor(self.times, dtype=torch.float32),\n",
    "            torch.tensor(self.y, dtype=torch.float32)\n",
    "        )\n",
    "        self.train_loader = DataLoader(self.dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        # Инициализация модели\n",
    "        if edit_model:\n",
    "            self.model = edit_model(input_size=X.shape[1] + 1, hidden_layers=hidden_layers, output_size=2, dropout_rate=dropout_rate).to(self.device)\n",
    "        else:\n",
    "            self.model = self.DefaultSimpleMLP(input_size=self.X.shape[1] + 1, hidden_layers=hidden_layers, output_size=2, dropout_rate=dropout_rate).to(self.device)\n",
    "        \n",
    "        # Логирование структуры модели\n",
    "        self.writer.add_graph(self.model, torch.randn(1, self.X.shape[1] + 1).to(self.device))\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, 'min', patience=patience, factor=factor)\n",
    "\n",
    "    class DefaultSimpleMLP(nn.Module):\n",
    "        def __init__(self, input_size, hidden_layers, output_size=2, dropout_rate=0.5):\n",
    "            super().__init__()\n",
    "    \n",
    "            self.layers = []\n",
    "            self.activations = []  # Список для хранения активаций\n",
    "            self.hooks = []  # Список для хранения hook'ов\n",
    "    \n",
    "            # Входной слой\n",
    "            layer = nn.Linear(input_size, hidden_layers[0])\n",
    "            self.layers.append(layer)\n",
    "            self.add_activation_logging(layer)  # Добавить логирование активаций\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.BatchNorm1d(hidden_layers[0]))  # Batch Normalization\n",
    "            self.layers.append(nn.Dropout(dropout_rate))\n",
    "    \n",
    "            # Скрытые слои\n",
    "            for i in range(1, len(hidden_layers)):\n",
    "                layer = nn.Linear(hidden_layers[i - 1], hidden_layers[i])\n",
    "                self.layers.append(layer)\n",
    "                self.add_activation_logging(layer)  # Добавить логирование активаций\n",
    "                self.layers.append(nn.ReLU())\n",
    "                self.layers.append(nn.BatchNorm1d(hidden_layers[i]))  # Batch Normalization\n",
    "                self.layers.append(nn.Dropout(dropout_rate))\n",
    "    \n",
    "            # Выходной слой\n",
    "            layer = nn.Linear(hidden_layers[-1], output_size)\n",
    "            self.layers.append(layer)\n",
    "    \n",
    "            self.model = nn.Sequential(*self.layers)\n",
    "    \n",
    "        def add_activation_logging(self, layer):\n",
    "            def hook(module, input, output):\n",
    "                self.activations.append(output.detach().cpu())\n",
    "    \n",
    "            self.hooks.append(layer.register_forward_hook(hook))\n",
    "    \n",
    "        def clear_activations(self):\n",
    "            \"\"\"Очистка сохранённых активаций.\"\"\"\n",
    "            self.activations = []\n",
    "    \n",
    "        def forward(self, x):\n",
    "            return self.model(x)\n",
    "    \n",
    "        def close_hooks(self):\n",
    "            \"\"\"Закрытие hook'ов после окончания обучения.\"\"\"\n",
    "            for hook in self.hooks:\n",
    "                hook.remove()\n",
    "                \n",
    "    @staticmethod\n",
    "    def prepare_data(df):\n",
    "        \"\"\"\n",
    "        Преобразование входных данных: разделение на реальные и мнимые части.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Входные данные.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Обработанные данные.\n",
    "        \"\"\"\n",
    "        df.columns = df.columns.str.lower()\n",
    "        df['input'] = df['input'].apply(lambda x: complex(x))\n",
    "        df['output'] = df['output'].apply(lambda x: complex(x))\n",
    "        df['input_real'] = df['input'].apply(lambda x: x.real)\n",
    "        df['input_imag'] = df['input'].apply(lambda x: x.imag)\n",
    "        df['output_real'] = df['output'].apply(lambda x: x.real)\n",
    "        df['output_imag'] = df['output'].apply(lambda x: x.imag)\n",
    "        df = df.drop(['input', 'output'], axis=1)\n",
    "        df = df.set_index('time')  # 'time' колонка теперь индекс\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def get_device(select=None):\n",
    "        \"\"\"\n",
    "        Определение устройства для вычислений (CPU или GPU).\n",
    "\n",
    "        Args:\n",
    "            select (str, optional): Выбор устройства ('cpu', 'cuda'). По умолчанию None.\n",
    "\n",
    "        Returns:\n",
    "            torch.device: Устройство для вычислений.\n",
    "        \"\"\"\n",
    "        if select is None or select == 'cuda':\n",
    "            return torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        return torch.device('cpu')\n",
    "\n",
    "    @staticmethod\n",
    "    def create_dataset(df, M, K):\n",
    "        \"\"\"\n",
    "        Создание обучающих данных на основе полиномиальной модели с памятью и добавлением времени.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): Обработанные данные.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Матрица признаков X, объединенные целевые значения y и временные метки times.\n",
    "        \"\"\"\n",
    "        x_real = df['input_real'].values\n",
    "        x_imag = df['input_imag'].values\n",
    "        y_real = df['output_real'].values[M:]\n",
    "        y_imag = df['output_imag'].values[M:]\n",
    "        times = df.index.values[M:]\n",
    "\n",
    "        # Объединение реальных и мнимых частей в один целевой вектор\n",
    "        y = np.stack([y_real, y_imag], axis=1)\n",
    "\n",
    "        N = len(x_real)\n",
    "        X = np.zeros((N, (M + 1) * K * 2), dtype=np.float64)\n",
    "        for n in range(M, N):\n",
    "            index = 0\n",
    "            for m in range(M + 1):\n",
    "                for k in range(1, K + 1):\n",
    "                    X[n, index] = np.abs(x_real[n - m])**(k-1) * x_real[n - m]\n",
    "                    X[n, index + 1] = np.abs(x_imag[n - m])**(k-1) * x_imag[n - m]\n",
    "                    index += 2\n",
    "        return X[M:], y, times\n",
    "        \n",
    "    def initialize_log_dir(self, experiment_name):\n",
    "        \"\"\"\n",
    "        Проверяет существование директории для логов и создаёт новую, если она существует.\n",
    "\n",
    "        Args:\n",
    "            experiment_name (str): Имя эксперимента для создания директории.\n",
    "\n",
    "        Returns:\n",
    "            SummaryWriter: Экземпляр SummaryWriter для TensorBoard.\n",
    "        \"\"\"\n",
    "        self.log_dir = f'logs/{experiment_name}'  # Базовый путь для логов\n",
    "        # Проверка существования директории и генерация нового имени, если необходимо\n",
    "        i = 0\n",
    "        while os.path.exists(self.log_dir):\n",
    "            self.log_dir = f'logs/{experiment_name}_{i}'\n",
    "            i += 1\n",
    "        os.makedirs(log_dir)  # Создание директории\n",
    "        return SummaryWriter(log_dir=self.log_dir)  # Инициализация SummaryWriter\n",
    "\n",
    "    def l1_l2_regularization(self):\n",
    "        l1_norm = sum(p.abs().sum() for p in self.model.parameters())\n",
    "        l2_norm = sum((p ** 2).sum() for p in self.model.parameters())\n",
    "        return self.l1_lambda * l1_norm + self.l2_lambda * l2_norm\n",
    "    \n",
    "    def train(self, max_early_stopping_counter=5):\n",
    "        \"\"\"\n",
    "        Обучение модели на объединенных целевых данных (реальная и мнимая части).\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        early_stopping_counter = 0\n",
    "        best_rmse = float('inf')\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            total_rmse = 0\n",
    "            progress_bar = tqdm(self.train_loader, desc=f\"Epoch {epoch+1}/{self.epochs}\", unit=\"batch\")\n",
    "\n",
    "            for batch_idx, (X_batch, times_batch, y_batch) in enumerate(progress_bar):\n",
    "                X_batch, times_batch, y_batch = X_batch.to(self.device), times_batch.to(self.device), y_batch.to(self.device)\n",
    "\n",
    "                # Объединение временных меток с входными признаками\n",
    "                X_with_times = torch.cat((X_batch, times_batch.unsqueeze(1)), dim=1)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                pred = self.model(X_with_times)\n",
    "                loss = self.criterion(pred, y_batch)\n",
    "                rmse = torch.sqrt(loss)  # RMSE\n",
    "                rmse.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                total_rmse += rmse.item()\n",
    "\n",
    "                # Логирование в TensorBoard\n",
    "                self.writer.add_scalar('Training/RMSE', rmse.item(), epoch * len(self.train_loader) + batch_idx)\n",
    "\n",
    "                # Получение текущего значения learning rate\n",
    "                current_learning_rate = self.optimizer.param_groups[0]['lr']\n",
    "                progress_bar.set_postfix(rmse=f\"{rmse:.10f}\", lr=f\"{current_learning_rate:.6f}\")\n",
    "\n",
    "            avg_rmse = total_rmse / len(self.train_loader)\n",
    "            self.history[\"epoch\"].append(epoch + 1)\n",
    "            self.history[\"rmse\"].append(avg_rmse)\n",
    "\n",
    "            # Логирование средней RMSE в TensorBoard\n",
    "            self.writer.add_scalar('Training/Average_RMSE', avg_rmse, epoch)\n",
    "            self.writer.add_scalar('Learning Rate', self.optimizer.param_groups[0]['lr'], epoch)\n",
    "\n",
    "            # Логирование распределения весов для каждого слоя\n",
    "            for name, param in self.model.named_parameters():\n",
    "                self.writer.add_histogram(f'Weights/{name}', param, epoch)\n",
    "                if param.grad is not None:\n",
    "                    self.writer.add_histogram(f'Gradients/{name}', param.grad, epoch)\n",
    "\n",
    "            # Обновление learning rate scheduler\n",
    "            self.scheduler.step(avg_rmse)\n",
    "\n",
    "            # Early Stopping\n",
    "            if avg_rmse < best_rmse:\n",
    "                best_rmse = avg_rmse\n",
    "                early_stopping_counter = 0\n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "\n",
    "            if early_stopping_counter >= max_early_stopping_counter:  # Параметр patience для Early Stopping\n",
    "                print(\"Early stopping activated.\")\n",
    "                break\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{self.epochs}, RMSE: {avg_rmse:.6f}\")\n",
    "            \n",
    "            \n",
    "    def evaluate(self):\n",
    "        \"\"\"\n",
    "        Оценка модели после обучения.\n",
    "        \n",
    "        Returns:\n",
    "            float: Значение RMSE.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        all_preds = []\n",
    "        all_true = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_batch, times_batch, y_batch in self.train_loader:\n",
    "                X_batch, times_batch, y_batch = X_batch.to(self.device), times_batch.to(self.device), y_batch.to(self.device)\n",
    "                \n",
    "                # Объединение временных меток с входными признаками\n",
    "                X_with_times = torch.cat((X_batch, times_batch.unsqueeze(1)), dim=1)\n",
    "\n",
    "                pred = self.model(X_with_times)\n",
    "                \n",
    "                all_preds.append(pred.cpu().numpy())\n",
    "                all_true.append(y_batch.cpu().numpy())\n",
    "\n",
    "        # Конкатенация всех предсказаний и истинных значений\n",
    "        self.pred = np.concatenate(all_preds)\n",
    "        self.true = np.concatenate(all_true)\n",
    "        \n",
    "        # Извлечение реальной и мнимой частей\n",
    "        self.pred_real = self.pred[:, 0]\n",
    "        self.true_real = self.true[:, 0]\n",
    "        self.pred_imag = self.pred[:, 1]\n",
    "        self.true_imag = self.true[:, 1]\n",
    "        \n",
    "        # Вычисление RMSE для реальной и мнимой части\n",
    "        rmse_real = np.sqrt(mean_squared_error(self.true_real, self.pred_real))\n",
    "        rmse_imag = np.sqrt(mean_squared_error(self.true_imag, self.pred_imag))\n",
    "    \n",
    "        # Логируем RMSE в TensorBoard\n",
    "        self.writer.add_scalar('Evaluation/REAL', rmse_real, len(self.history[\"epoch\"]) - 1)\n",
    "        self.writer.add_scalar('Evaluation/IMAG', rmse_imag, len(self.history[\"epoch\"]) - 1)\n",
    "\n",
    "        return rmse_real, rmse_imag\n",
    "        \n",
    "    def save_model_pt(self, filename_prefix='node', save_dir='models'):\n",
    "        \"\"\"\n",
    "        Сохраняет всю модель PyTorch в формате .pt.\n",
    "\n",
    "        Args:\n",
    "            filename_prefix (str, optional): Префикс имени файла. По умолчанию 'node'.\n",
    "            save_dir (str, optional): Директория для сохранения модели. По умолчанию 'models'.\n",
    "        \"\"\"\n",
    "        # Создаем папку, если ее нет\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        # Генерируем имя файла с текущей датой и временем\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"{filename_prefix}_{timestamp}_{self.model_id}.pt\"\n",
    "\n",
    "        # Полный путь к файлу\n",
    "        filepath = os.path.join(save_dir, filename)\n",
    "\n",
    "        # Сохраняем ВСЮ модель\n",
    "        torch.save(self.model, filepath)\n",
    "        print(f\"Model saved in {filepath}\")\n",
    "\n",
    "    def plot_training_history(self, window_size=5):\n",
    "        \"\"\"\n",
    "        Строит графики истории обучения модели, отображая RMSE на каждой эпохе и скользящее среднее.\n",
    "        \"\"\"\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "        # Преобразуем список эпох для оси X\n",
    "        epochs = self.history[\"epoch\"]\n",
    "    \n",
    "        # Вычисляем скользящее среднее\n",
    "        rmse = np.array(self.history[\"rmse\"])\n",
    "        moving_avg = np.convolve(rmse, np.ones(window_size)/window_size, mode='valid')\n",
    "    \n",
    "        # Первый график: Полная история\n",
    "        axs[0].plot(epochs, rmse, marker='o', linestyle='-', color='b', markersize=5, label='RMSE')\n",
    "        axs[0].plot(epochs[window_size-1:], moving_avg, color='r', label=f'Moving Average (window size={window_size})')\n",
    "        axs[0].set_xlabel('Epoch')\n",
    "        axs[0].set_ylabel('Average Loss')\n",
    "        axs[0].set_title('Loss Function (Full History)')\n",
    "        axs[0].grid(True)\n",
    "        axs[0].legend()\n",
    "    \n",
    "        # Второй график: Половина истории\n",
    "        mid_index = len(epochs) // 2\n",
    "        axs[1].plot(epochs[mid_index:], rmse[mid_index:], marker='o', linestyle='-', color='b', markersize=5, label='RMSE')\n",
    "        axs[1].plot(epochs[mid_index + window_size - 1:], moving_avg[mid_index:], color='r', label=f'Moving Average (window size={window_size})')\n",
    "        axs[1].set_xlabel('Epoch')\n",
    "        axs[1].set_ylabel('Average RMSE')\n",
    "        axs[1].set_title('Loss Function (Second Half of Training)')\n",
    "        axs[1].grid(True)\n",
    "        axs[1].legend()\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_predictions(self, time_start=0, time_end=1.01e-4):\n",
    "        \"\"\"\n",
    "        Построение графиков предсказанных и фактических значений в заданном временном диапазоне.\n",
    "\n",
    "        Args:\n",
    "            time_start (float, optional): Начальное время для отображения. По умолчанию 0.\n",
    "            time_end (float, optional): Конечное время для отображения. По умолчанию 1.01e-4.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        pred_real, pred_imag = self.pred[:, 0], self.pred[:, 1]\n",
    "        true_real, true_imag = self.true[:, 0], self.true[:, 1]\n",
    "\n",
    "        # Фильтрация данных по указанному временному диапазону\n",
    "        time_mask = (self.times >= time_start) & (self.times <= time_end)\n",
    "\n",
    "        selected_times = self.times[time_mask]\n",
    "        \n",
    "        # Фильтрация предсказаний и фактических значений по временному диапазону\n",
    "        pred_real = pred_real[time_mask]\n",
    "        pred_imag = pred_imag[time_mask]\n",
    "        true_real = true_real[time_mask]\n",
    "        true_imag = true_imag[time_mask]\n",
    "    \n",
    "        # Проверка, чтобы убедиться, что данные не пустые\n",
    "        if len(selected_times) == 0:\n",
    "            print(f\"No data points found between {time_start} and {time_end}.\")\n",
    "            return\n",
    "        \n",
    "        # Построение графиков\n",
    "        fig, axs = plt.subplots(2, 1, figsize=(15, 8))\n",
    "\n",
    "        # Реальная часть\n",
    "        axs[0].plot(selected_times, true_real, label='True Real', linestyle='-', color='red')\n",
    "        axs[0].plot(selected_times, pred_real, label='Predicted Real', linestyle='-', color='blue')\n",
    "        axs[0].set_xlabel('Time')\n",
    "        axs[0].set_ylabel('Real Part')\n",
    "        axs[0].legend()\n",
    "        axs[0].grid(True)\n",
    "\n",
    "        # Мнимая часть\n",
    "        axs[1].plot(selected_times, true_imag, label='True Imag', linestyle='-', color='red')\n",
    "        axs[1].plot(selected_times, pred_imag, label='Predicted Imag', linestyle='-', color='blue')\n",
    "        axs[1].set_xlabel('Time')\n",
    "        axs[1].set_ylabel('Imaginary Part')\n",
    "        axs[1].legend()\n",
    "        axs[1].grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def draw_plot_signal(self, signal_type, time_start=0, time_end=1e-6):\n",
    "        \"\"\"\n",
    "        Построение графика сигнала в указанном временном диапазоне.\n",
    "        \n",
    "        Args:\n",
    "            signal_type (str): Тип сигнала ('input' или 'output').\n",
    "            time_start (float): Начальное время.\n",
    "            time_end (float): Конечное время.\n",
    "        \"\"\"\n",
    "        # Фильтрация данных по временной отметке\n",
    "        filtered_data = self.df[(self.df.index >= time_start) & (self.df.index <= time_end)]\n",
    "        time = filtered_data.index\n",
    "\n",
    "        # Построение графика реальной и мнимой частей сигнала\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(time, filtered_data[f'{signal_type}_real'], label=f'{signal_type} Real Part', color='blue', linestyle='-')\n",
    "        plt.plot(time, filtered_data[f'{signal_type}_imag'], label=f'{signal_type} Imaginary Part', color='red', linestyle='-')\n",
    "        \n",
    "        plt.title(f'{signal_type.capitalize()} Signal from {time_start} to {time_end} seconds')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    def print_model_summary(self, filename_prefix=\"model_parameters\", save_dir='history'):\n",
    "        \"\"\"\n",
    "        Выводит информацию о модели и сохраняет её параметры и их размерности в CSV файл.\n",
    "\n",
    "        Args:\n",
    "            filename_prefix (str, optional): Префикс имени файла. По умолчанию 'model_parameters'.\n",
    "            save_dir (str, optional): Директория для сохранения файла. По умолчанию 'history'.\n",
    "        \"\"\"\n",
    "        # Создаем папку, если ее нет\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        # Генерируем имя файла с текущей датой и временем\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"{filename_prefix}_{timestamp}_{self.model_id}.csv\"\n",
    "\n",
    "        # Полный путь к файлу\n",
    "        filepath = os.path.join(save_dir, filename)\n",
    "        \n",
    "        df_params = pd.DataFrame(columns=['Parameter name', 'Parameter shape', 'Parameter count'])\n",
    "        \n",
    "        print(f\"Model architecture: {self.model}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        total_params = 0\n",
    "        for name, param in self.model.named_parameters():\n",
    "            print(f\"Parameter name: {name}\")\n",
    "            print(f\"Parameter shape: {param.shape}\")\n",
    "            param_count = torch.numel(param)\n",
    "            print(f\"Parameter count: {param_count}\")\n",
    "            print(\"-\" * 30)\n",
    "\n",
    "            # Добавляем информацию о параметре в DataFrame\n",
    "            df_params.loc[len(df_params)] = [name, param.shape, param_count] \n",
    "            \n",
    "            total_params += param_count\n",
    "\n",
    "        print(f\"Total trainable parameters: {total_params}\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Сохраняем DataFrame в CSV файл\n",
    "        # df_params.to_csv(filepath, index=False)\n",
    "        \n",
    "        # print(f\"Print model saved in {filepath}\")\n",
    "\n",
    "    def log_predictions_to_tensorboard(self):\n",
    "        \"\"\"\n",
    "        Логирование всех предсказанных и фактических значений в TensorBoard.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        pred_real, pred_imag = self.pred[:, 0], self.pred[:, 1]\n",
    "        true_real, true_imag = self.true[:, 0], self.true[:, 1]\n",
    "\n",
    "        # Логирование в TensorBoard для реальных значений\n",
    "        for i in range(len(self.pred)):\n",
    "            self.writer.add_scalars(\n",
    "                'Predictions/Real', \n",
    "                {\n",
    "                    'Predicted': pred_real[i],\n",
    "                    'True': true_real[i],\n",
    "                },\n",
    "                global_step=i\n",
    "            )\n",
    "    \n",
    "        # Логирование в TensorBoard для мнимых значений\n",
    "        for i in range(len(self.pred)):\n",
    "            self.writer.add_scalars(\n",
    "                'Predictions/Imag', \n",
    "                {\n",
    "                    'Predicted ': pred_imag[i],\n",
    "                    'True': true_imag[i]\n",
    "                },\n",
    "                global_step=i\n",
    "            )\n",
    "\n",
    "        print(f\"All predictions logged to TensorBoard.\")\n",
    "\n",
    "    def log_hparams_and_metrics(self, rmse_real, rmse_imag):\n",
    "        hparams = {\n",
    "            'batch_size': self.batch_size,\n",
    "            'learning_rate': self.learning_rate,\n",
    "            'M': self.M,\n",
    "            'K': self.K,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "            'l1_lambda': self.l1_lambda,\n",
    "            'l2_lambda': self.l2_lambda,\n",
    "            'num_epochs': self.epochs\n",
    "        }\n",
    "    \n",
    "        # Логирование гиперпараметров и метрик\n",
    "        self.writer.add_hparams(hparams, { \n",
    "            'rmse_real': rmse_real,\n",
    "            'rmse_imag': rmse_imag \n",
    "        }, run_name=int(time.time()))\n",
    "        \n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369a79cc-4ed6-45b5-8dba-36c604262189",
   "metadata": {},
   "source": [
    "### Кастомные модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ca27100-90db-4e1e-8dd9-ede2c443fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, output_size=2, dropout_rate=0.0):\n",
    "        \"\"\"\n",
    "        Простая классическая нейросеть MLP для регрессии реальной и мнимой частей сигнала.\n",
    "\n",
    "        Args:\n",
    "            input_size (int): Размерность входного слоя (количество признаков).\n",
    "            hidden_layers (list): Список размеров скрытых слоев.\n",
    "            output_size (int, optional): Размерность выходного слоя. По умолчанию 2 (для реальной и мнимой части).\n",
    "            dropout_rate (float, optional): Вероятность отключения нейронов. По умолчанию 0.0 (без отключения).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        # Входной слой\n",
    "        layers.append(nn.Linear(input_size, hidden_layers[0]))\n",
    "        layers.append(nn.ReLU())\n",
    "        if dropout_rate > 0:\n",
    "            layers.append(nn.Dropout(dropout_rate))  # Добавляем Dropout\n",
    "\n",
    "        # Скрытые слои\n",
    "        for i in range(1, len(hidden_layers)):\n",
    "            layers.append(nn.Linear(hidden_layers[i - 1], hidden_layers[i]))\n",
    "            layers.append(nn.ReLU())\n",
    "            if dropout_rate > 0:\n",
    "                layers.append(nn.Dropout(dropout_rate))  # Добавляем Dropout\n",
    "\n",
    "        # Выходной слой\n",
    "        layers.append(nn.Linear(hidden_layers[-1], output_size))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Прямой проход через MLP.\n",
    "        Args:\n",
    "            x (torch.Tensor): Входные данные.\n",
    "        Returns:\n",
    "            torch.Tensor: Прогнозы (реальная и мнимая части).\n",
    "        \"\"\"\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd25ee0-7c3b-4572-ac4b-bd95863cf4fb",
   "metadata": {},
   "source": [
    "## Установка параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5318b9d4-7551-4cff-9e55-30b4229a57f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 3  # Глубина памяти\n",
    "K = 3  # Степень полинома"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2114bb8c-421d-46a5-8aeb-526ea38621c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1024*5\n",
    "learning_rate=1e-3\n",
    "epochs=10\n",
    "hidden_layers=[2**6, 2**7, 2**7, 2**6]\n",
    "dropout_rate=0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1107c2e0-f00e-492e-976f-5f017e032c84",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m\n",
      "Cell \u001b[0;32mIn[5], line 32\u001b[0m, in \u001b[0;36mMemoryPolynomialNNTrainer.__init__\u001b[0;34m(self, df, M, K, batch_size, learning_rate, epochs, hidden_layers, dropout_rate, l1_lambda, l2_lambda, patience, factor, edit_model, device, experiment_name)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4()) \u001b[38;5;66;03m# Генерация уникального ID\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemory_polynomial\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment_name \u001b[38;5;28;01melse\u001b[39;00m experiment_name\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize_log_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment_name)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Подготовка данных\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_dataset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf, M, K)\n",
      "Cell \u001b[0;32mIn[5], line 186\u001b[0m, in \u001b[0;36mMemoryPolynomialNNTrainer.initialize_log_dir\u001b[0;34m(self, experiment_name)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# Проверка существования директории и генерация нового имени, если необходимо\u001b[39;00m\n\u001b[1;32m    185\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(log_dir):\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    188\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'log_dir' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Создание экземпляра класса с настройкой гиперпараметров\n",
    "model_nn = MemoryPolynomialNNTrainer(\n",
    "    df=df, \n",
    "    M=M, K=K, \n",
    "    batch_size=batch_size,\n",
    "    learning_rate=learning_rate, \n",
    "    epochs=epochs, \n",
    "    hidden_layers=hidden_layers,\n",
    "    dropout_rate=dropout_rate,\n",
    "    # edit_model=SimpleMLP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ec734a5-def7-4eca-90b6-7e6e099fbf3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_nn\u001b[38;5;241m.\u001b[39mprint_model_summary()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_nn' is not defined"
     ]
    }
   ],
   "source": [
    "model_nn.print_model_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491660ac-a28a-428d-a608-4d9150a17cb4",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4106899-1bb3-4f0d-aeae-e116d502c610",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model_nn.train(max_early_stopping_counter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22cfb8f-f52f-481a-8a73-e769942bd169",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn.plot_training_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69be16e-1d85-4c7e-b78f-ab090e69d66e",
   "metadata": {},
   "source": [
    "## Предсказание и сохранение модели после обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7150dad4-04eb-4884-8201-3f2ae078efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_real, rmse_imag = model_nn.evaluate()\n",
    "\n",
    "print(f\"Evaluation RMSE (Real): {rmse_real:.6f}\")\n",
    "print(f\"Evaluation RMSE (Imag): {rmse_imag:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778fd454-5671-4aa9-86fc-fecf6dd6cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_nn.log_predictions_to_tensorboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3d6504-9715-49dc-a254-199aca917b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn.log_hparams_and_metrics(rmse_real, rmse_imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129fd2fa-7203-44a9-9311-d46368c74d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_nn.save_model_pt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218a1331-c02d-4147-8ada-4d1b20cf87d5",
   "metadata": {},
   "source": [
    "## Демонстрация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba1ae12-7591-4b15-9be5-cde190eafa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn.plot_predictions(time_start=0, time_end=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0d17e9-e09d-4641-95ed-fc971185bcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn.plot_predictions(time_start=1e-4, time_end=1.003e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473e486c-d755-4969-b87e-856bce56a3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn.plot_predictions(time_start=3e-4, time_end=3.001e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6183e155-5eb5-48b8-bcb3-82202d8b08d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn.plot_predictions(time_start=3.005e-4, time_end=3.006e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
